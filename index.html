<!DOCTYPE html 
     PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
     "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Grzegorz Chrupała</title>
  <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond&display=swap" rel="stylesheet">        
  <style type="text/css">
    body {
	font-family: 'EB Garamond', serif;
	font-size: 130%;
	position: absolute;
	max-width: 800px;
	left: 0;
	right: 0;
	margin: auto;
	padding: 1em;
    }
    abbr[title] { cursor: help }
    img { border:0 ; border-radius:10px }
    dt { font-weight: bold; font-size: 0.8em }
    dd { margin-bottom:1em }
    h2 { margin-top: 3em; }
    
    ul#publications li { padding: 0.5em; }
    
    div#toc {   
    border: 1px dashed black ; 
    border-radius:5px ;
    max-width: 15em;
    padding: 0.5em;
    }
    div#toc ul {
    list-style-type: none;
    }
  </style>
  

<script src="toc.js" type="text/javascript"></script>
</head>

<body onload="generateTOC(document.getElementById('toc'));"> 
<div itemscope itemtype="http://schema.org/Person" id="main">
<img style="float:right;margin:1em;margin-right:3em;width:10em" src="grz600.jpg"
     alt="Grzegorz" itemprop="image"/>


<h1><a itemprop="name"><span itemprop="givenName">Grzegorz</span> <span itemprop="familyName">Chrupała</span></a></h1>
<div style="font-family: Gentium,'Gentium Plus',GentiumAlt,'DejaVu Sans','Segoe UI','Lucida Grande','Charis SIL','Doulos SIL','TITUS Cyberbit Basic','Code2000','Lucida Sans Unicode',sans-serif;">/ˈɡʐɛɡɔʂ xru'pawa/<br> 
    <audio style="height: 1em;" controls="controls" src="name.wav">Your browser does not support the HTML5 Audio element.
    </audio>
  </div>
<div itemprop="description">
<p> I am an <span itemprop="jobTitle">Associate Professor</span> at
the department of Cognitive Science and Artificial Intelligence at 
  <span itemprop="affiliation" itemscope
  itemtype="http://schema.org/Organization"><span itemprop="name">Tilburg
  University</span></span>, where I lead the Multimodal
  Language Learning (ℳℒ²) Lab.
</p>
<p>
I received my PhD from
the <a href="http://www.computing.dcu.ie/">School of Computing</a> at
Dublin City University. After that I worked as a researcher at the
Spoken Language Systems group
at <a href="http://www.uni-saarland.de/en/">Saarland
    University</a>. <br>See full <a href="#section6">bio</a>.
</p>

<h2 style="display: inline;">Research</h4> at the <span title="Multimodal
  Language Learning">ℳℒ²</span> Lab 
is inspired by the ease which
young children show for picking up any language they are exposed to,
sometimes several languages at the same time, and seemingly with
little effort and practically no explicit instruction. The information
they rely on is messy and unstructured, but it is rich and multimodal,
including speech and gestures, visual and auditory perception and
interaction with other people. In contrast the typical way computers
learn language is by reading billions of words of written text, at
best complemented by captioned static photos. In our lab we work on
enabling machines to access rich data in multiple modalities, and find
systematic connections between them as a way to learn to understand
language in a more natural and data-efficient manner. Our approach
will help us explore the limits of human-like learning, and if
successful will enable computers to deal not only with the world's
largest languages, but also with those with
little written material, or no writing system at all.
    


<p style="color:gray">In my free time
  I <a href="https://www.goodreads.com/review/list/8777275-grzegorz-chrupa-a?shelf=read">read</a>
  and take <a href="https://www.instagram.com/gchrupala/">photos.</a>
</p>

<p><strong>Note to prospective PhD students</strong>: Please check 
    the <a href="#section1">News</a> section below as well as
    my <a href="https://twitter.com/gchrupala">Twitter account</a> for
    announcements of available positions.
</p>

</div>

<div id="toc"></div>



<h2>News</h2>

<p><a rel="me" href="https://twitter.com/gchrupala">Twitter</a> | <a rel="me" href="https://sigmoid.social/@gchrupala">Mastodon</a></p>



<h3>Recent</h3>

<ul>
  <li>Paper accepted to Interspeech 2023: <a href="https://doi.org/10.48550/arXiv.2305.18957">Wave to Syntax: Probing spoken language models for syntax</a>.
  <li>Position paper accepted to the Findings of the ACL 2023: <a href="https://arxiv.org/abs/2305.04572">Putting Natural in Natural Language Processing
</a>.
  <li>Paper accepted to EACL
  2023: <a href="https://arxiv.org/abs/2301.12971">Quantifying Context
  Mixing in Transformers</a>.
  <li>Chris Emmery successfully defended his PhD dissertation
  on <a href="https://arxiv.org/abs/2301.04230">User-Centered Security
      in Natural Language Processing</a>.
  </ul>

<h2>People</h2>
  
<ul>
  <li><a href="https://nl.linkedin.com/in/gfshen">Gaofei Shen</a> PhD candidate in
    the <a href="https://interpretingdl.github.io/projects">InDeep</a>
    project.
  <li><a href="https://gsarti.com/">Gabriele Sarti</a>. PhD candidate in
    the <a href="https://interpretingdl.github.io/projects">InDeep</a>
    project.
  <li><a href="https://hmohebbi.github.io/">Hosein Mohebbi</a>. PhD candidate in
    the <a href="https://interpretingdl.github.io/projects">InDeep</a>
    project.
  </ul>
  
  <h3>Alumni</h3>
  <ul>
      <li><a href="https://cmry.github.io/">Chris Emmery</a>. PhD
      thesis: <a href="https://arxiv.org/abs/2301.04230">User-Centered Security in Natural Language Processing</a>.
      <li><a href="https://bhigy.github.io/">Bertrand
	Higy</a>. Postdoc, Understanding visually grounded spoken language
      via multi-tasking.
    <li><a href="https://www.esciencecenter.nl/team/dr-patrick-bos/">Patrick
	Bos</a>. E-science engineer, Understanding visually grounded spoken language
      via multi-tasking.
    <li><a href="https://www.esciencecenter.nl/team/christiaan-meijer-msc/">Christiaan Meijer</a>.
      E-science engineer, Understanding visually grounded spoken language
      via multi-tasking.
    <li><a href="https://kadarakos.github.io/">Ákos Kádár</a>. PhD
      thesis: <a href="https://kadarakos.github.io/assets/dissertation.pdf">Learning
	Visually Grounded and Multilingual Representations</a>.
    </ul>
    


<h2>Publications</h2>
<p>For the complete list of publications check:
  <a href="http://scholar.google.com/citations?user=p6m63xoAAAAJ&sortby=pubdate">Google
    Scholar</a> |
  <a href="https://www.semanticscholar.org/author/Grzegorz-Chrupala/2756960?q=&sort=influence&ae=false">Semantic
    Scholar</a> |
  <a href="https://dblp.org/pers/hd/c/Chrupala:Grzegorz">DBLP</a> |
  <a href="https://www.aclweb.org/anthology/people/g/grzegorz-chrupala/">ACL
  Anthology</a> |
  <a href="https://orcid.org/0000-0001-9498-6912">ORCID</a>
</p>


<h3>Selected papers</h3>
<ol>
  <li>Nikolaus, M., Alishahi, A. & Chrupała, G. (2022). Learning English with Peppa Pig. <em>Transactions of the Association for Computational Linguistics</em>, 10, 922–936.
    <br>
      <a href="https://doi.org/10.1162/tacl_a_00498">Paper</a>
      |
      <a href="https://github.com/gchrupala/peppa/">Code</a>
    </li>
    
  <li>Chrupała, G. (2022). Visually grounded models of spoken
  language: A survey of datasets, architectures and evaluation
  techniques. <em>Journal of Artificial Intelligence Research,</em> 73,
    673-707.<br>
      <a href="https://doi.org/10.1613/jair.1.12967">Paper</a>
      
    </li>
    
  <li>Chrupała, G., & Alishahi, A. (2019). Correlating Neural
  and Symbolic Representations of Language. In Proceedings of the 57th
  Annual Meeting of the Association for Computational Linguistics
  (pp. 2952-2962).<br/>
    <a href="https://doi.org/10.18653/v1/P19-1283">Paper</a> |
    <a href="https://github.com/gchrupala/correlating-neural-and-symbolic-representations-of-language">Code</a>
      </li>
  
      
  <li>Chrupała, G., Gelderloos, L., & Alishahi, A. (2017).
    Representations of language in a model of visually grounded
  speech signal. In Proceedings of the 55th Annual Meeting of the
  Association for Computational Linguistics (Volume 1: Long Papers)
  (pp. 613-622).<br>
      <a href="http://dx.doi.org/10.18653/v1/P17-1057">Paper</a>
      | <a href="https://github.com/gchrupala/visually-grounded-speech">Code</a>
    </li>
  
  <li>Kádár, A., Chrupała, G., & Alishahi, A. (2017). Representation
  of linguistic form and function in recurrent neural
  networks. <em>Computational Linguistics,</em> 43(4):761-780.<br>
      <a href="http://dx.doi.org/10.1162/COLI_a_00300">Paper</a>
      | <a href="https://github.com/gchrupala/rep-form-function">Code</a>
    </li>
  </ol>



<h2>Recent Talks</h2>
<ul>
  <li>Putting <em>Natural</em> in NLP. University of
  Groningen. <a href="papers/unify-slides.pdf">Slides</a></li>
  <li>Learning language from Peppa Pig. ILLC seminar, University of Amsterdam.</li>
  <li>Visually Grounded Models of Spoken Language and their
    Analysis. Lecture at ALPS Winter School. <a href="https://youtube.com/playlist?list=PLlKYDs3RAfJyH6WFPfkSCo-pcNaMcEAEI">Video</a>
    </li>
  <li>Investigating neural representations of speech and language. Keynote at
    the Nordic Conference on Computational Linguistics (NoDaLiDa),
    October 2019. <a href="papers/nodalida-slides.pdf">Slides</a>
  </li>
</ul>



<h2>Supervision</h2>  
<p>Selected MSc theses</p>

<ul>
  <li>Jean Constantin. 2022. <a href="https://tilburguniversity.on.worldcat.org/oclc/1371190842">Identification of causal
  discourse relations in French text using machine-translated training
      resources</a>. Tilburg University.</li>
  
  <li>Kristel van Rooij. 2021. <a href="https://tilburguniversity.on.worldcat.org/oclc/1319426781">Gender classification of
  first names using Long Short-Term Memory recurrent neural networks
  and support vector machine in various countries</a>. Tilburg
    University.
    </li>
  <li>Aayushi
    Pandey. 2020. <a href="https://tilburguniversity.on.worldcat.org/oclc/1291689112">Emotion
      recognition in a model of visually grounded speech</a>. Tilburg
    University.</li>
  <li>Dmitrijs
    Surenans. 2020. <a href="https://tilburguniversity.on.worldcat.org/oclc/1292464689">Machine
      Learning Explainability In Finance: An Application to Default Risk
      Analysis.</a> Tilburg University.</li>
  <li>Dennis de Groot. 2019. <a href="http://arno.uvt.nl/show.cgi?fid=148087">Finding Structure in Neural Network
      Activation Patterns via Representational Similarity and
      Convolutional Kernels</a>. Tilburg University.</li>
  <li>Mark van der Laan. 2018. <a href="papers/laan.pdf">Encoding of speaker identity in a Neural Network
      model of Visually Grounded Speech perception</a>. Tilburg University.</li>
  <li>Lieke Gelderloos. 2016. Tilburg University.
    <a href="http://arno.uvt.nl/show.cgi?fid=141323">Levels of
      representation in a recurrent neural model of visually grounded
      language learning</a>. Tilburg University.
    See also Coling 2016 paper:
    <a href="https://arxiv.org/abs/1610.03342">From phonemes to
      images: levels of representation in a recurrent neural model of
      visually grounded language learning</a>.
  </li>
  <li>Ákos Kádár.
    2014. <a href="http://tilburguniversity.worldcat.org/oclc/893945123">Grounded
      learning for source code component retrieval</a>. Tilburg
    University</li>
  
  <li>Antoaneta
    Baltadzhieva. 2014. <a href="http://tilburguniversity.worldcat.org/oclc/893945405">Predicting
      question quality in question answering forums</a>. Tilburg
    University</li>

  <li>Huijing Deng. 2013. Probabilistic Models of API
    Retrieval. Saarland University.  (See also Deng and
    Chrupała. 2014. <a href="http://www.lrec-conf.org/proceedings/lrec2014/pdf/106_Paper.pdf">Semantic
      approaches to software component retrieval with English queries</a>.
    LREC.)
  </li>
  
</ul>


<h2>Bio</h2>

Grzegorz Chrupała is an Associate Professor at the Department of
Cognitive Science and Artificial Intelligence at Tilburg
University, where he leads the Multimodal Language Learning (or ℳℒ²) Lab.
Previously he did postdoctoral research at the Spoken
Language Systems group at Saarland University. He received his
doctoral degree from the School of Computing at Dublin City
University.

His research focuses on computational models of learning (spoken)
language in naturalistic multimodal settings, as well as analysis and
interpretation of representations emerging in deep learning
architectures.

He regularly serves as Senior Area Chair for major NLP and AI conferences
such as ACL and EMNLP.  He was one of the creators of the popular
BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for
NLP. His research has been funded by the Dutch Research Council (NWO),
via ASDI and NWA-ORC grants.


<h2>Contact</h2>
<div itemprop="address" itemscope itemtype="http://schema.org/PostalAddress">
  Grzegorz Chrupała</a><br/>
  Department of Cognitive Science and Artificial Intelligence<br/>
  Tilburg University<br/></span>
  <span itemprop="postOfficeBoxNumber">PO Box 90153</span><br/>
  <span itemprop="postalCode">5000 LE</span> <span itemprop="addressLocality">Tilburg</span><br/>
  <span itemprop="addressCountry">The Netherlands</span>
</div>

<p>
  Twitter: <a href="https://twitter.com/gchrupala">@gchrupala</a><br/>
  Mastodon: <a href="https://sigmoid.social/@gchrupala">@gchrupala@sigmoid.social</a><br/>
  Web:    <a href="http://grzegorz.chrupala.me" itemprop="url">grzegorz.chrupala.me</a><br/>
  Email:  <span itemprop="email">grzegorz@chrupala.me</span>
</p>
          
</div>
</body>
</html>
