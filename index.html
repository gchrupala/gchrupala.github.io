<!DOCTYPE html 
     PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
     "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Grzegorz Chrupała</title>
  <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond&display=swap" rel="stylesheet">        
  <style type="text/css">
    body {
	font-family: 'EB Garamond', serif;
	font-size: 130%;
	position: absolute;
	max-width: 800px;
	left: 0;
	right: 0;
	margin: auto;
	padding: 1em;
    }
    abbr[title] { cursor: help }
    img { border:0 ; border-radius:10px }
    dt { font-weight: bold; font-size: 0.8em }
    dd { margin-bottom:1em }
    h2 { margin-top: 3em; }
    
    ul#publications li { padding: 0.5em; }
    
    div#toc {   
    border: 1px dashed black ; 
    border-radius:5px ;
    max-width: 15em;
    padding: 0.5em;
    }
    div#toc ul {
    list-style-type: none;
    }
  </style>
  

<script src="toc.js" type="text/javascript"></script>
</head>

<body onload="generateTOC(document.getElementById('toc'));"> 
<div itemscope itemtype="http://schema.org/Person" id="main">
<img style="float:right;margin:1em;margin-right:3em;width:10em" src="grz600.jpg"
     alt="Grzegorz" itemprop="image"/>


<h1><a itemprop="name"><span itemprop="givenName">Grzegorz</span> <span itemprop="familyName">Chrupała</span></a></h1>
<div style="font-family: Gentium,'Gentium Plus',GentiumAlt,'DejaVu Sans','Segoe UI','Lucida Grande','Charis SIL','Doulos SIL','TITUS Cyberbit Basic','Code2000','Lucida Sans Unicode',sans-serif;">/ˈɡʐɛɡɔʂ xru'pawa/<br> 
    <audio style="height: 1em;" controls="controls" src="name.wav">Your browser does not support the HTML5 Audio element.
    </audio>
  </div>
<div itemprop="description">
<p> I am an <span itemprop="jobTitle">Associate Professor</span> at
the department of Cognitive Science and Artificial Intelligence at 
  <span itemprop="affiliation" itemscope
  itemtype="http://schema.org/Organization"><span itemprop="name">Tilburg
  University</span></span>.
</p>
<p>
I received my PhD from
the School of Computing at
Dublin City University. After that I worked as a researcher at the
Spoken Language Systems group
at Saarland University. I am
interested in computation in biological and artificial systems, and
connections between them.
    <br>See full <a href="#section6">bio</a>. 
</p>


<div style="color:gray; margin-top:2em; margin-bottom:3em">
  <p>In my free time
  I like <a href="https://www.goodreads.com/review/list/8777275-grzegorz-chrupa-a?shelf=read&sort=date_added">reading</a>,
  taking <a href="https://www.instagram.com/gchrupala/">photos,</a>
  and <a href="https://onfoot.substack.com">hiking</a>.
    </p>
</div>

<div style="margin-bottom:2em">
  <h2 style="display: inline;">Research</h4> in my lab focuses
  on computational approaches to multimodal communication.
We often take inspiration from 
the ease which young children show for picking up languages they
are exposed to with little effort and no explicit
instruction. The information they rely on is messy and unstructured,
but it is rich and multimodal, including speech and gestures, visual
and auditory stimuli, and interaction with other people.  In
contrast, the typical way computers learn language is by reading
billions of words of written text.

  <p>We work on enabling machines to access rich data in multiple
modalities and find systematic connections between them as a way to
learn language in a more natural and data-efficient manner.
  <p>We explore the limits of human-like learning, aiming to teach
computers to deal not only with the world's largest languages, but
also with those with little written material, or no writing system at all.
    
<p>We also develop, apply, and evaluate techniques for understanding
computations in deep learning architectures.

    
</div>


</div>

<div id="toc"></div>



<h2>News</h2>

<ul>
  <li>I have joined the board of the Dutch <a href="https://openspraaktechnologie.org/">Open Speech Technology Foundation.</a></li>
  
  <li>I am publicity co-chair for Interspeech 2025.</li>
  <li>I am an action editor for TACL.</li>
  <li>Paper accepted to NAACL 2024: <a href="https://doi.org/10.18653/v1/2024.naacl-long.239">Encoding of lexical tone in self-supervised models of spoken language</a>.
  <li>I'm talking about putting <em>natural</em> back into Natural
  Language Processing at the 2nd Dutch Speech Tech Day.
  <li>My course on <a href="https://github.com/gchrupala/neurospoken">Neural models of spoken language</a> at the LOT
  Winter School 2024</a>.
  <li>Paper accepted to ICLR 2024: <a href="https://doi.org/10.48550/arXiv.2310.01188">Quantifying the Plausibility of Context Reliance in Neural Machine Translation</a>.
  

  </ul>

<h2>People</h2>
  
<ul>
  
  <li><a href="https://www.gaofeishen.com/">Gaofei Shen</a>. PhD
    candidate, Interpretability techniques for spoken language models.
  <li><a href="https://gsarti.com/">Gabriele Sarti</a>. PhD candidate,
    User-centric interpretability for neural machine translation.
  <li><a href="https://hmohebbi.github.io/">Hosein Mohebbi</a>. PhD
    candidate, Analyzing and interpreting deep neural models of
    language.
    <li><a href="https://research.tilburguniversity.edu/en/persons/lisa-lepp">Lisa
    Lepp</a>. PhD candidate, Machine Translation for sign and spoken
      languages.
      <li><a href="https://research.tilburguniversity.edu/en/persons/c%C3%A9line-angonin">Céline
      Angonin</a>. PhD candidate, bioacoustics.
  </ul>
  
  <h3>Alumni</h3>
  <ul>
      <li><a href="https://cmry.github.io/">Chris Emmery</a>. PhD
      thesis: <a href="https://arxiv.org/abs/2301.04230">User-Centered Security in Natural Language Processing</a>.
      <li><a href="https://www.linkedin.com/in/bertrandhigy/?locale=en_US">Bertrand
	Higy</a>. Postdoc, Understanding visually grounded spoken language
      via multi-tasking.
    <li><a href="https://www.esciencecenter.nl/team/dr-patrick-bos/">Patrick
	Bos</a>. E-science engineer, Understanding visually grounded spoken language
      via multi-tasking.
    <li><a href="https://www.esciencecenter.nl/team/christiaan-meijer-msc/">Christiaan Meijer</a>.
      E-science engineer, Understanding visually grounded spoken language
      via multi-tasking.
    <li><a href="https://kadarakos.github.io/">Ákos Kádár</a>. PhD
      thesis: <a href="https://kadarakos.github.io/assets/dissertation.pdf">Learning
	Visually Grounded and Multilingual Representations</a>.
    </ul>
    


<h2>Publications</h2>
<p>For the complete list of publications check:
  <a href="http://scholar.google.com/citations?user=p6m63xoAAAAJ&sortby=pubdate">Google
    Scholar</a> |
  <a href="https://www.semanticscholar.org/author/Grzegorz-Chrupala/2756960?q=&sort=influence&ae=false">Semantic
    Scholar</a> |
  <a href="https://dblp.org/pers/hd/c/Chrupala:Grzegorz">DBLP</a> |
  <a href="https://www.aclweb.org/anthology/people/g/grzegorz-chrupala/">ACL
  Anthology</a> |
  <a href="https://orcid.org/0000-0001-9498-6912">ORCID</a>
</p>


<h3>Selected papers</h3>
<ol>

  <li>Shen, G., Alishahi, A., Bisazza, A., Chrupała, G. (2023) Wave to
  Syntax: Probing spoken language models for syntax. In
  Proc. Interspeech 2023 (pp. 1259–1263).<br>
      <a href="https://doi.org/10.21437/Interspeech.2023-679">Paper</a>
    </li>
    
  <li>Nikolaus, M., Alishahi, A. & Chrupała, G. (2022). Learning
  English with Peppa Pig. <em>Transactions of the Association for
  Computational Linguistics</em>, 10, 922–936.
    <br>
      <a href="https://doi.org/10.1162/tacl_a_00498">Paper</a> |
      <a href="https://github.com/gchrupala/peppa/">Code</a>
    </li>
    
  <li>Chrupała, G. (2022). Visually grounded models of spoken
  language: A survey of datasets, architectures and evaluation
  techniques. <em>Journal of Artificial Intelligence Research,</em>
  73, 673–707.<br>
      <a href="https://doi.org/10.1613/jair.1.12967">Paper</a>
      
    </li>
    
  <li>Chrupała, G., & Alishahi, A. (2019). Correlating Neural and
  Symbolic Representations of Language. In Proceedings of the 57th
  Annual Meeting of the Association for Computational Linguistics
  (pp. 2952–2962).<br/>
    <a href="https://doi.org/10.18653/v1/P19-1283">Paper</a> |
    <a href="https://github.com/gchrupala/correlating-neural-and-symbolic-representations-of-language">Code</a>
      </li>
  
      
  <li>Chrupała, G., Gelderloos, L., & Alishahi, A. (2017).
    Representations of language in a model of visually grounded speech
    signal. In Proceedings of the 55th Annual Meeting of the
    Association for Computational Linguistics (Volume 1: Long Papers)
    (pp. 613–622).<br>
      <a href="http://dx.doi.org/10.18653/v1/P17-1057">Paper</a>
      | <a href="https://github.com/gchrupala/visually-grounded-speech">Code</a>
    </li>
  
  </ol>



<h2>Recent Talks</h2>
<ul>
  <li>Putting <em>Natural</em> in NLP. University of Groningen.</li>
  <li>Learning language from Peppa Pig. ILLC seminar, University of Amsterdam.</li>
  <li>Visually Grounded Models of Spoken Language and their
    Analysis. Lecture at ALPS Winter
    School. <a href="https://youtube.com/playlist?list=PLlKYDs3RAfJyH6WFPfkSCo-pcNaMcEAEI">Video</a>
    </li>
  <li>Investigating neural representations of speech and language. Keynote at
    the Nordic Conference on Computational Linguistics (NoDaLiDa),
    October 2019.</li>
</ul>



<h2>Supervision</h2>  
<p>Selected MSc theses</p>

<ul>
  <li>Jean Constantin. 2022. <a href="https://tilburguniversity.on.worldcat.org/oclc/1371190842">Identification of causal
  discourse relations in French text using machine-translated training
      resources</a>. Tilburg University.</li>
  
  <li>Kristel van Rooij. 2021. <a href="https://tilburguniversity.on.worldcat.org/oclc/1319426781">Gender classification of
  first names using Long Short-Term Memory recurrent neural networks
  and support vector machine in various countries</a>. Tilburg
    University.
    </li>
  <li>Aayushi
    Pandey. 2020. <a href="https://tilburguniversity.on.worldcat.org/oclc/1291689112">Emotion
      recognition in a model of visually grounded speech</a>. Tilburg
    University.</li>
  <li>Dmitrijs
    Surenans. 2020. <a href="https://tilburguniversity.on.worldcat.org/oclc/1292464689">Machine
      Learning Explainability In Finance: An Application to Default Risk
      Analysis.</a> Tilburg University.</li>
</ul>


<h2>Bio</h2>

<p>Grzegorz Chrupała is an Associate Professor at the Department of
Cognitive Science and Artificial Intelligence at Tilburg
University.
Previously he did postdoctoral research at the Spoken
Language Systems group at Saarland University. He received his
doctoral degree from the School of Computing at Dublin City
University.

<p>He is interested in computation in biological and artificial systems,
and connections between them.  His research focuses especially on
computational models of learning (spoken) language in naturalistic
multimodal settings, as well as analysis and interpretation of
representations emerging in deep learning architectures.

<p>He is an Action Editor for TACL, and regularly serves as Senior
Area Chair for major NLP and AI conferences such as ACL and EMNLP.  He
was one of the creators of the popular BlackboxNLP Workshop on
Analyzing and Interpreting Neural Networks for NLP. His research has
been funded by the Dutch Research Council (NWO).


<h2>Contact</h2>
<div itemprop="address" itemscope itemtype="http://schema.org/PostalAddress">
  Grzegorz Chrupała</a><br/>
  Department of Cognitive Science and Artificial Intelligence<br/>
  Tilburg University<br/></span>
  <span itemprop="postOfficeBoxNumber">PO Box 90153</span><br/>
  <span itemprop="postalCode">5000 LE</span> <span itemprop="addressLocality">Tilburg</span><br/>
  <span itemprop="addressCountry">The Netherlands</span>
</div>

<p>
  Bluesky: <a href="https://bsky.app/profile/grzegorz.chrupala.me">@grzegorz.chrupala.me</a></br>
  Twitter: <a href="https://twitter.com/gchrupala">@gchrupala</a><br/>
  Web:    <a href="http://grzegorz.chrupala.me" itemprop="url">grzegorz.chrupala.me</a><br/>
  Email:  <span itemprop="email">grzegorz@chrupala.me</span>
</p>
          
</div>
</body>
</html>
