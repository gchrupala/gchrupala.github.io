<!DOCTYPE html 
     PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
     "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Grzegorz Chrupała</title>
  <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond&display=swap" rel="stylesheet">        
  <style type="text/css">
    body {
	font-family: 'EB Garamond', serif;
	font-size: 130%;
	position: absolute;
	max-width: 800px;
	left: 0;
	right: 0;
	margin: auto;
	padding: 1em;
    }
    abbr[title] { cursor: help }
    img { border:0 ; border-radius:10px }
    dt { font-weight: bold; font-size: 0.8em }
    dd { margin-bottom:1em }
    h2 { margin-top: 3em; }
    
    ul#publications li { padding: 0.5em; }
    
    div#toc {   
    border: 1px dashed black ; 
    border-radius:5px ;
    max-width: 15em;
    padding: 0.5em;
    }
    div#toc ul {
    list-style-type: none;
    }
  </style>
  

<script src="toc.js" type="text/javascript"></script>
</head>

<body onload="generateTOC(document.getElementById('toc'));"> 
<div itemscope itemtype="http://schema.org/Person" id="main">
<img style="float:right;margin:1em;margin-right:3em;width:10em" src="grz600.jpg"
     alt="Grzegorz" itemprop="image"/>


<h1><a itemprop="name"><span itemprop="givenName">Grzegorz</span> <span itemprop="familyName">Chrupała</span></a></h1>
<div style="font-family: Gentium,'Gentium Plus',GentiumAlt,'DejaVu Sans','Segoe UI','Lucida Grande','Charis SIL','Doulos SIL','TITUS Cyberbit Basic','Code2000','Lucida Sans Unicode',sans-serif;">/ˈɡʐɛɡɔʂ xru'pawa/<br> 
    <audio style="height: 1em;" controls="controls" src="name.wav">Your browser does not support the HTML5 Audio element.
    </audio>
  </div>
<div itemprop="description">
<p> I am an <span itemprop="jobTitle">Associate Professor</span> affiliated with the Center for Cognitive Science and Artificial Intelligence at 
  <span itemprop="affiliation" itemscope
  itemtype="http://schema.org/Organization"><span itemprop="name">Tilburg
  University</span></span>.
</p>
<p>
I received my PhD from the School of Computing at Dublin City
University. After that I worked as a postdoctoral researcher at the
Spoken Language Systems group at Saarland University. I am interested
in computation in biological and artificial systems, and connections
between them.
    <br>See full <a href="#section6">bio</a>. 
</p>


<div style="color:gray; margin-top:2em; margin-bottom:3em">
  <p>In my free time
  I like <a href="https://www.goodreads.com/review/list/8777275-grzegorz-chrupa-a?shelf=read&sort=date_added">reading</a>,
  taking <a href="https://photos.app.goo.gl/cDzGiN2tAC1S3csG9">photos,</a>
  and <a href="https://onfoot.substack.com">hiking</a>.
    </p>
</div>

<div style="margin-bottom:2em">
  <h2 style="display: inline;">Research</h4> in my lab focuses on
  computational approaches to multimodal communication.  We take
  inspiration from the ease which young children show for picking up
  languages they are exposed to with little effort and no explicit
  instruction. The information they rely on is messy and unstructured,
  yet it is rich and multimodal, including speech and gestures, visual
  and auditory stimuli, and interaction with other people.  In
  contrast, the typical way computers learn language is by reading
  billions of words of written text.

  <p>We work on enabling machines to access rich data in multiple
modalities and find systematic connections between them as a way to
learn language in a more natural and data-efficient manner.
  <p>We explore the limits of human-like learning, aiming to teach
computers to deal not only with the world's largest languages, but
also with those with little written material, or no writing system at all.
    
<p>We also develop, apply, and evaluate techniques for understanding
computations in deep learning architectures.

    
</div>


</div>

<div id="toc"></div>



<h2>News</h2>

<ul>
  <li>Paper accepted to TACL: <a href="https://doi.org/10.48550/arXiv.2503.03044">QE4PE: Word-level Quality Estimation for Human Post-Editing</a>.
  <li>We taught a <a href="https://interpretingdl.github.io/speech-interpretability-tutorial/">tutorial on Interpretability Techniques for Speech
  Models at Interspeech 2025</a>.
  <li>Paper published at Interspeech
  2025: <a href="https://www.isca-archive.org/interspeech_2025/shen25b_interspeech.html#">On
  the reliability of feature attribution methods for speech
      classification</a>.
    <li>Hosein presented <a href="https://actionable-interpretability.github.io/posters/poster_AIW2025%20-%20Hosein%20Mohebbi.pdf">Posthoc Disentanglement of Textual and Acoustic Features
in Self-Supervised Speech Encoders</a> at an ICML workshop on
      actionable interpretability.
  <li>I have joined the board of the Dutch <a href="https://openspraaktechnologie.org/">Open Speech Technology Foundation.</a></li>
  
  <li>I am publicity co-chair for Interspeech 2025.</li>
  <li>I am an action editor for TACL.</li>

  </ul>

<h2>People</h2>
  
<ul>
  
  <li><a href="https://www.gaofeishen.com/">Gaofei Shen</a>. PhD
    candidate, Interpretability techniques for spoken language models.
  <li><a href="https://gsarti.com/">Gabriele Sarti</a>. PhD candidate,
    User-centric interpretability for neural machine translation.
  <li><a href="https://hmohebbi.github.io/">Hosein Mohebbi</a>. PhD
    candidate, Analyzing and interpreting deep neural models of
    language.
    <li><a href="https://research.tilburguniversity.edu/en/persons/lisa-lepp">Lisa
    Lepp</a>. PhD candidate, Machine Translation for sign and spoken
      languages.
      <li><a href="https://research.tilburguniversity.edu/en/persons/c%C3%A9line-angonin">Céline
      Angonin</a>. PhD candidate, bioacoustics.
  </ul>
  
  <h3>Alumni</h3>
  <ul>
      <li><a href="https://cmry.github.io/">Chris Emmery</a>. PhD
      thesis: <a href="https://arxiv.org/abs/2301.04230">User-Centered Security in Natural Language Processing</a>.
      <li><a href="https://www.linkedin.com/in/bertrandhigy/?locale=en_US">Bertrand
	Higy</a>. Postdoc, Understanding visually grounded spoken language
      via multi-tasking.
    <li><a href="https://www.esciencecenter.nl/team/dr-patrick-bos/">Patrick
	Bos</a>. E-science engineer, Understanding visually grounded spoken language
      via multi-tasking.
    <li><a href="https://www.esciencecenter.nl/team/christiaan-meijer-msc/">Christiaan Meijer</a>.
      E-science engineer, Understanding visually grounded spoken language
      via multi-tasking.
    <li><a href="https://kadarakos.github.io/">Ákos Kádár</a>. PhD
      thesis: <a href="https://kadarakos.github.io/assets/dissertation.pdf">Learning
	Visually Grounded and Multilingual Representations</a>.
    </ul>
    


<h2>Publications</h2>
<p>For the complete list of publications check:
  <a href="http://scholar.google.com/citations?user=p6m63xoAAAAJ&sortby=pubdate">Google
    Scholar</a> |
  <a href="https://www.semanticscholar.org/author/Grzegorz-Chrupala/2756960?q=&sort=influence&ae=false">Semantic
    Scholar</a> |
  <a href="https://dblp.org/pers/hd/c/Chrupala:Grzegorz">DBLP</a> |
  <a href="https://www.aclweb.org/anthology/people/g/grzegorz-chrupala/">ACL
  Anthology</a> |
  <a href="https://orcid.org/0000-0001-9498-6912">ORCID</a>
</p>


<h3>Selected papers</h3>
<ol>

  <li>Shen, G., Alishahi, A., Bisazza, A., Chrupała, G. (2023) Wave to
  Syntax: Probing spoken language models for syntax. In
  Proc. Interspeech 2023 (pp. 1259–1263).<br>
      <a href="https://doi.org/10.21437/Interspeech.2023-679">Paper</a>
      | <a href="https://github.com/techsword/wave-to-syntax">Code</a>
    </li>
    
  <li>Nikolaus, M., Alishahi, A. & Chrupała, G. (2022). Learning
  English with Peppa Pig. <em>Transactions of the Association for
  Computational Linguistics</em>, 10, 922–936.
    <br>
      <a href="https://doi.org/10.1162/tacl_a_00498">Paper</a> |
      <a href="https://github.com/gchrupala/peppa/">Code</a>
    </li>
    
  <li>Chrupała, G. (2022). Visually grounded models of spoken
  language: A survey of datasets, architectures and evaluation
  techniques. <em>Journal of Artificial Intelligence Research,</em>
  73, 673–707.<br>
      <a href="https://doi.org/10.1613/jair.1.12967">Paper</a>
      
    </li>
    
  <li>Chrupała, G., & Alishahi, A. (2019). Correlating Neural and
  Symbolic Representations of Language. In Proceedings of the 57th
  Annual Meeting of the Association for Computational Linguistics
  (pp. 2952–2962).<br/>
    <a href="https://doi.org/10.18653/v1/P19-1283">Paper</a> |
    <a href="https://github.com/gchrupala/correlating-neural-and-symbolic-representations-of-language">Code</a>
      </li>
  
      
  <li>Chrupała, G., Gelderloos, L., & Alishahi, A. (2017).
    Representations of language in a model of visually grounded speech
    signal. In Proceedings of the 55th Annual Meeting of the
    Association for Computational Linguistics (Volume 1: Long Papers)
    (pp. 613–622).<br>
      <a href="http://dx.doi.org/10.18653/v1/P17-1057">Paper</a>
      | <a href="https://github.com/gchrupala/visually-grounded-speech">Code</a>
    </li>
  
  </ol>



<h2>Selected Talks</h2>
<ul>
  <li>Promises and pitfalls of unified NLP, NLG in the Lowlands, 
  2025

  <li>Putting <em>natural</em> back into Natural Language Processing,
    Second Dutch Speech Tech Day, 2024
    
    <li>Opening the black box of foundation models. Indeep
      Outreach/Amsterdam AI Meetup, 2023.
      
    <li>TAISIG Talks - The opportunities and limitations of Deep
      Learning, Tilburg University, 2022.
      
    <li>Learning language from Peppa Pig. ILLC seminar, University of
    Amsterdam, 2022.

    <li>Visually Grounded Models of Spoken Language and their Analysis
        and Evaluation. Lectures on Computational Linguistics, AILC,
        2021.

</ul>



<h2>Supervision</h2>  
<p>Selected MSc theses</p>

<ul>
  <li>Jean Constantin. 2022. <a href="https://tilburguniversity.on.worldcat.org/oclc/1371190842">Identification of causal
  discourse relations in French text using machine-translated training
      resources</a>. Tilburg University.</li>
  
  <li>Kristel van Rooij. 2021. <a href="https://tilburguniversity.on.worldcat.org/oclc/1319426781">Gender classification of
  first names using Long Short-Term Memory recurrent neural networks
  and support vector machine in various countries</a>. Tilburg
    University.
    </li>
  <li>Aayushi
    Pandey. 2020. <a href="https://tilburguniversity.on.worldcat.org/oclc/1291689112">Emotion
      recognition in a model of visually grounded speech</a>. Tilburg
    University.</li>
  <li>Dmitrijs
    Surenans. 2020. <a href="https://tilburguniversity.on.worldcat.org/oclc/1292464689">Machine
      Learning Explainability In Finance: An Application to Default Risk
      Analysis.</a> Tilburg University.</li>
</ul>


<h2>Bio</h2>

<p>Grzegorz Chrupała is an Associate Professor at the Center for
Cognitive Science and Artificial Intelligence at Tilburg
University.
Previously he did postdoctoral research at the Spoken
Language Systems group at Saarland University. He received his
doctoral degree from the School of Computing at Dublin City
University.

<p>He is interested in computation in biological and artificial systems,
and connections between them.  His research focuses especially on
computational models of learning (spoken) language in naturalistic
multimodal settings, as well as analysis and interpretation of
representations emerging in deep learning architectures.

<p>He is an Action Editor for TACL, and regularly serves as Senior
Area Chair for major NLP and AI conferences such as ACL and EMNLP.  He
was one of the creators of the popular BlackboxNLP Workshop on
Analyzing and Interpreting Neural Networks for NLP. His research has
been funded by the Dutch Research Council (NWO).


<h2>Contact</h2>
<div itemprop="address" itemscope itemtype="http://schema.org/PostalAddress">
  Grzegorz Chrupała</a><br/>
  Department of Cognitive Science and Artificial Intelligence<br/>
  Tilburg University<br/></span>
  <span itemprop="postOfficeBoxNumber">PO Box 90153</span><br/>
  <span itemprop="postalCode">5000 LE</span> <span itemprop="addressLocality">Tilburg</span><br/>
  <span itemprop="addressCountry">The Netherlands</span>
</div>

<p>
  Bluesky: <a href="https://bsky.app/profile/grzegorz.chrupala.me">@grzegorz.chrupala.me</a></br>
  Twitter: <a href="https://twitter.com/gchrupala">@gchrupala</a><br/>
  Web:    <a href="http://grzegorz.chrupala.me" itemprop="url">grzegorz.chrupala.me</a><br/>
  Email:  <span itemprop="email">grzegorz@chrupala.me</span>
</p>
          
</div>
</body>
</html>
